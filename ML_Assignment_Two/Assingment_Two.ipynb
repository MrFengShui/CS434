{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Numerical Library\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# Image manipulation library\n",
    "from PIL import Image\n",
    "\n",
    "# Limit printout to 3 decimal places\n",
    "np.set_printoptions(precision=3,suppress=True)\n",
    "\n",
    "# Allows for printing inline for jupyter notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# http://scikit-learn.org/stable/tutorial/machine_learning_map/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load datasets and store in ndarray\n",
    "raw_train = genfromtxt('usps-4-9-train.csv', delimiter=',')\n",
    "raw_test = genfromtxt('usps-4-9-test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off known target values\n",
    "y_train = raw_train[:,256]\n",
    "y_test = raw_test[:,256]\n",
    "\n",
    "# Add dimension to y_train and transpose\n",
    "y_train = y_train[np.newaxis].T\n",
    "y_test = y_test[np.newaxis].T\n",
    "\n",
    "# Remove column 256 from X\n",
    "raw_train = np.delete(raw_train, 256, axis=1)\n",
    "raw_test = np.delete(raw_test, 256, axis=1)\n",
    "\n",
    "# Function to create array of dummy ones and returned \n",
    "# columnar vector\n",
    "def make_dummy_vector(target):\n",
    "    temp = np.ones(len(target))\n",
    "    return temp[np.newaxis].T\n",
    "\n",
    "# Create dummy 1 values\n",
    "dummy_train = make_dummy_vector(raw_train)\n",
    "dummy_test = make_dummy_vector(raw_test)\n",
    "\n",
    "# Add dummy data to feature matrices\n",
    "X_train = np.concatenate((dummy_train, raw_train), axis=1)\n",
    "X_test = np.concatenate((dummy_test, raw_test), axis=1)\n",
    "\n",
    "X_train = X_train.T\n",
    "X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   0.    0.    0.    0.    0.    0.    0.    0.   11.  133.  195.    7.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   12.  120.\n",
      "   220.  255.  149.    2.    0.    0.    0.    0.    0.    0.    0.   20.\n",
      "   113.  172.  239.  255.  255.   72.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.  122.  255.  253.  174.  105.  155.  255.    3.    0.    0.\n",
      "     0.    0.    0.    0.    0.   73.  243.  183.   17.    0.    0.  144.\n",
      "   244.    2.    0.    0.    0.    0.   30.   28.    0.    0.    0.    0.\n",
      "     0.    0.    0.   98.  201.    0.    0.   15.  102.  179.  255.  174.\n",
      "     0.    0.    0.    0.    0.    0.    0.  155.  212.   90.  167.  253.\n",
      "   255.  206.   94.   16.    0.    0.    0.    0.    0.    0.   25.  223.\n",
      "   255.  239.  139.   64.   43.    0.    0.    0.    0.    0.    0.    0.\n",
      "    37.  154.  251.  255.  166.   12.    0.    0.    0.    0.    0.    0.\n",
      "     0.   22.  116.  205.  252.  173.   97.  255.  109.    0.    0.    0.\n",
      "     0.    0.    0.    0.   90.  248.  198.   93.   14.    0.   16.  255.\n",
      "    29.    0.    0.    0.    0.    0.    0.    0.   62.   29.    0.    0.\n",
      "     0.    0.   61.  249.   23.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.  119.  203.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  177.  180.\n",
      "     0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    7.  238.  134.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.    0.   14.  148.   32.    0.    0.    0.    0.\n",
      "     0.    0.    0.    0.]]\n"
     ]
    }
   ],
   "source": [
    "# Data for a single sample\n",
    "print raw_train[0][np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displays a single sample for context\n",
    "def visualize_sample(data,target):\n",
    "    temp = np.reshape(data[target][np.newaxis],(16,16))\n",
    "    img = Image.fromarray(temp)\n",
    "    img.show()\n",
    "    \n",
    "# Example call to function\n",
    "visualize_sample(raw_train, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Compute optimal weight vector w = (X^T * X)^-1 (X^T * Y)\n",
    "# def calc_w_vector(X, y):\n",
    "#     return np.dot(inv(np.dot(X.T,X)), np.dot(X.T,y))\n",
    "\n",
    "# w_train = calc_w_vector(X_train,y_train)\n",
    "# w_test = calc_w_vector(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computer linear regression function\n",
    "# target_function_train = np.dot(X_test,w_test)\n",
    "# target_function_test = np.dot(X_test,w_test)\n",
    "\n",
    "# # Plot the values gathered above\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.plot(target_function_train)\n",
    "# fig.suptitle('Linear Regression Function for X_train', fontsize=16)\n",
    "# plt.xlabel('Sample number', fontsize=16)\n",
    "# plt.ylabel('Intensity', fontsize=16)\n",
    "\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.plot(target_function_test)\n",
    "# fig.suptitle('Linear Regression Function for X_test', fontsize=16)\n",
    "# plt.xlabel('Sample number', fontsize=16)\n",
    "# plt.ylabel('Intensity', fontsize=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sigmoid function\n",
    "def calc_sigmoid(target_function):\n",
    "    return (1 / (1 + np.exp(-target_function)))\n",
    "\n",
    "# sigmoid_train = calc_sigmoid(target_function_train)\n",
    "# sigmoid_test = calc_sigmoid(target_function_test)\n",
    "\n",
    "# # Plot the values gathered above\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.plot(sigmoid_train)\n",
    "# fig.suptitle('Sigmoid Function for X_train', fontsize=16)\n",
    "# plt.xlabel('Sample number', fontsize=16)\n",
    "# plt.ylabel('Intensity', fontsize=16)\n",
    "\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.plot(sigmoid_test)\n",
    "# fig.suptitle('Sigmoid Function for X_test', fontsize=16)\n",
    "# plt.xlabel('Sample number', fontsize=16)\n",
    "# plt.ylabel('Intensity', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(257L, 1L)\n"
     ]
    }
   ],
   "source": [
    "print X_train[:,0][np.newaxis].T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_batch: (257L, 1L)\n",
      "d: (257L, 1L)\n",
      "[[-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]\n",
      " [-155366.4]]\n"
     ]
    }
   ],
   "source": [
    "# Initialize weight vector with zeros\n",
    "# Configure batch learning, LR = learning rate\n",
    "def batch_learning(X,y,n,LR):\n",
    "    w_batch = np.zeros(len(X))[np.newaxis].T\n",
    "    print 'w_batch: %s' % (w_batch.shape,)\n",
    "    d = np.zeros(len(X))[np.newaxis].T\n",
    "    print 'd: %s' % (d.shape,)\n",
    "    \n",
    "    #Range argument limits batch size\n",
    "    for i in range(n):\n",
    "        y_hat = calc_sigmoid((np.dot(w_batch,X_train[:,n][np.newaxis])))\n",
    "        #print 'y_train[i]: %s' % (y_train.shape,)\n",
    "        #print 'y_hat[i]: %s' % (y_hat[i].shape,)\n",
    "        error = np.subtract(y_train[i],y_hat[i])\n",
    "        #print 'd shape: %s' % (d.shape,)\n",
    "        #print error[np.newaxis].T.shape\n",
    "        #d = d + np.dot(np.add(d, error[np.newaxis].T),X_train[i][np.newaxis])\n",
    "        d = np.add(d,np.dot(error[np.newaxis], X_train[:,n][np.newaxis].T))\n",
    "    w_batch = np.add(w_batch,np.dot(LR,d)) \n",
    "    #print w_batch\n",
    "    \n",
    "batch_learning(X_train,y_train,256,0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_batch: (257L, 1L)\n",
      "(257L, 1400L)\n",
      "(1400L,)\n"
     ]
    }
   ],
   "source": [
    "# Attempt at batch learning algorithm\n",
    "# for X_sample, y_sample in zip(X_train, y_train):\n",
    "#     print X_sample, y_sample\n",
    "\n",
    "\n",
    "    #y_hat = (1/(1+np.exp(np.dot(-w_batch,X_train[0][np.newaxis]))))\n",
    "    y_hat = calc_sigmoid(np.dot(w_batch,X_train[0][np.newaxis]))\n",
    "    print y_hat.shape\n",
    "    error = np.subtract(y_train[0],y_hat[0])\n",
    "    print error.shape\n",
    "    # Repeat unitl convergence\n",
    "#     \n",
    "\n",
    "#     #print 'X_train[i][np.newaxis]: %s' % (X_train[n][np.newaxis].T.shape,)\n",
    "\n",
    "#   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print X_train[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print y_train[1200]\n",
    "print X_train.shape\n",
    "print w_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calc_sigmoid(np.dot(-X_train[0],w_batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print np.dot(-w_batch,X_train[0][np.newaxis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
