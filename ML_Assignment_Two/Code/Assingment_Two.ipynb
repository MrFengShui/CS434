{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from matplotlib import gridspec\n",
    "\n",
    "# Numerical Library\n",
    "import numpy as np\n",
    "from numpy import genfromtxt\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# Image manipulation library\n",
    "from PIL import Image\n",
    "\n",
    "# Limit printout to 3 decimal places\n",
    "np.set_printoptions(precision=3,suppress=True)\n",
    "\n",
    "# Allows for printing inline for jupyter notebook\n",
    "%matplotlib inline \n",
    "\n",
    "# http://scikit-learn.org/stable/tutorial/machine_learning_map/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load datasets and store in ndarray\n",
    "raw_train = genfromtxt('usps-4-9-train.csv', delimiter=',')\n",
    "raw_test = genfromtxt('usps-4-9-test.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.]\n",
      " [ 0.]\n",
      " [ 0.]\n",
      " ..., \n",
      " [ 1.]\n",
      " [ 1.]\n",
      " [ 1.]]\n"
     ]
    }
   ],
   "source": [
    "print raw_train[:,256][np.newaxis].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split off known target values\n",
    "y_train = raw_train[:,256]\n",
    "y_test = raw_test[:,256]\n",
    "\n",
    "# Add dimension to y_train and transpose\n",
    "y_train = y_train[np.newaxis].T\n",
    "y_test = y_test[np.newaxis].T\n",
    "\n",
    "# Remove column 256 from X\n",
    "raw_train = np.delete(raw_train, 256, axis=1)\n",
    "raw_test = np.delete(raw_test, 256, axis=1)\n",
    "\n",
    "## NOT COMPLETELY SURE WE NEED DUMMY ONES\n",
    "\n",
    "# Function to create array of dummy ones and returned \n",
    "# columnar vector\n",
    "def make_dummy_vector(target):\n",
    "   temp = np.ones(len(target))\n",
    "   return temp[np.newaxis].T\n",
    "\n",
    "# Create dummy 1 values\n",
    "dummy_train = make_dummy_vector(raw_train)\n",
    "dummy_test = make_dummy_vector(raw_test)\n",
    "\n",
    "# Add dummy data to feature matrices\n",
    "X_train = np.concatenate((dummy_train, raw_train), axis=1)\n",
    "X_test = np.concatenate((dummy_test, raw_test), axis=1)\n",
    "\n",
    "\n",
    "# In case we don't need dummy ones\n",
    "#X_train = raw_train\n",
    "#X_test = raw_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0.    0.    0.    0.    0.    0.    0.    0.   11.  133.  195.    7.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.   12.  120.\n",
      "  220.  255.  149.    2.    0.    0.    0.    0.    0.    0.    0.   20.\n",
      "  113.  172.  239.  255.  255.   72.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.  122.  255.  253.  174.  105.  155.  255.    3.    0.    0.\n",
      "    0.    0.    0.    0.    0.   73.  243.  183.   17.    0.    0.  144.\n",
      "  244.    2.    0.    0.    0.    0.   30.   28.    0.    0.    0.    0.\n",
      "    0.    0.    0.   98.  201.    0.    0.   15.  102.  179.  255.  174.\n",
      "    0.    0.    0.    0.    0.    0.    0.  155.  212.   90.  167.  253.\n",
      "  255.  206.   94.   16.    0.    0.    0.    0.    0.    0.   25.  223.\n",
      "  255.  239.  139.   64.   43.    0.    0.    0.    0.    0.    0.    0.\n",
      "   37.  154.  251.  255.  166.   12.    0.    0.    0.    0.    0.    0.\n",
      "    0.   22.  116.  205.  252.  173.   97.  255.  109.    0.    0.    0.\n",
      "    0.    0.    0.    0.   90.  248.  198.   93.   14.    0.   16.  255.\n",
      "   29.    0.    0.    0.    0.    0.    0.    0.   62.   29.    0.    0.\n",
      "    0.    0.   61.  249.   23.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.  119.  203.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.  177.  180.\n",
      "    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    7.  238.  134.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.    0.   14.  148.   32.    0.    0.    0.    0.\n",
      "    0.    0.    0.    0.]\n"
     ]
    }
   ],
   "source": [
    "# Data for a single sample\n",
    "print raw_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## This is not completely working, we need to figure out why the image seems upside down ##\n",
    "\n",
    "# Displays a single sample for context\n",
    "def visualize_sample(data,target):\n",
    "    temp = np.reshape(data[target],(16,16))\n",
    "    img = Image.fromarray(temp)\n",
    "    img.show()\n",
    "    \n",
    "# Example call to function\n",
    "visualize_sample(raw_train, 1200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NOT YET NEEDED, INCORRECT FIRST ATTEMPT AT ASSIGNMENT\n",
    "\n",
    "# Compute optimal weight vector w = (X^T * X)^-1 (X^T * Y)\n",
    "# def calc_w_vector(X, y):\n",
    "#     return np.dot(inv(np.dot(X.T,X)), np.dot(X.T,y))\n",
    "\n",
    "# w_train = calc_w_vector(X_train,y_train)\n",
    "# w_test = calc_w_vector(X_test,y_test)\n",
    "\n",
    "# Computer linear regression function\n",
    "# target_function_train = np.dot(X_test,w_test)\n",
    "# target_function_test = np.dot(X_test,w_test)\n",
    "\n",
    "# # Plot the values gathered above\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.plot(target_function_train)\n",
    "# fig.suptitle('Linear Regression Function for X_train', fontsize=16)\n",
    "# plt.xlabel('Sample number', fontsize=16)\n",
    "# plt.ylabel('Intensity', fontsize=16)\n",
    "\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.plot(target_function_test)\n",
    "# fig.suptitle('Linear Regression Function for X_test', fontsize=16)\n",
    "# plt.xlabel('Sample number', fontsize=16)\n",
    "# plt.ylabel('Intensity', fontsize=16)\n",
    "\n",
    "# sigmoid_train = calc_sigmoid(target_function_train)\n",
    "# sigmoid_test = calc_sigmoid(target_function_test)\n",
    "\n",
    "# # Plot the values gathered above\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.plot(sigmoid_train)\n",
    "# fig.suptitle('Sigmoid Function for X_train', fontsize=16)\n",
    "# plt.xlabel('Sample number', fontsize=16)\n",
    "# plt.ylabel('Intensity', fontsize=16)\n",
    "\n",
    "# fig = plt.figure(figsize=(9,6))\n",
    "# plt.plot(sigmoid_test)\n",
    "# fig.suptitle('Sigmoid Function for X_test', fontsize=16)\n",
    "# plt.xlabel('Sample number', fontsize=16)\n",
    "# plt.ylabel('Intensity', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate sigmoid function\n",
    "def calc_sigmoid(target_function):\n",
    "    return (1 / (1 + np.exp(-target_function)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\ipykernel\\__main__.py:3: RuntimeWarning: overflow encountered in exp\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "# Initialize weight vector with zeros\n",
    "# Configure batch learning, LR = learning rate\n",
    "def batch_learning(X,y,n,lrn_rate,iterations):\n",
    "    w_batch = np.zeros(len(X[0]))\n",
    "    \n",
    "    ## Repeat until convergence  \n",
    "    ctr = 0\n",
    "    for i in range(iterations):\n",
    "        d = np.zeros(len(X[0]))\n",
    "        #Range argument limits batch size\n",
    "        while(ctr < 1400):\n",
    "            for i in range(n):\n",
    "                y_hat_i = calc_sigmoid((np.dot(w_batch.T,X[ctr])))      \n",
    "                error = y[i] - y_hat_i\n",
    "                test = error * X[i]\n",
    "                d = np.add(d,test)\n",
    "                ctr += 1\n",
    "            modified_descent = lrn_rate * d\n",
    "            w_batch = np.add(w_batch,modified_descent) \n",
    "            print ctr\n",
    "    return w_batch\n",
    "\n",
    "    \n",
    "test = batch_learning(X_train,y_train,200,0.1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   -70.      -46.9    -231.7    -360.5    -580.65   -970.2   -1927.45\n",
      "  -3124.8   -4005.05  -3454.5   -1647.45   -991.9    -357.7    -181.65\n",
      "   -194.95   -934.5   -1088.5    -168.     -707.    -1395.8   -2728.6\n",
      "  -4622.1   -7245.35  -9311.4  -10104.85  -8564.85  -4675.3   -2408.35\n",
      "   -985.95   -694.75  -1625.4   -2468.55  -1369.9    -263.9    -988.75\n",
      "  -2529.1   -4505.9   -6765.5   -9042.6  -10456.95 -10551.1   -8744.05\n",
      "  -5188.05  -2592.8   -1495.9   -2158.45  -2805.95  -2576.    -1227.45\n",
      "   -345.1   -1951.25  -3431.05  -5227.95  -6644.05  -7641.2   -8208.2\n",
      "  -8515.85  -7957.95  -5195.4   -3086.65  -2965.9   -3136.35  -3054.8\n",
      "  -2667.7   -1440.95   -804.65  -2494.45  -4081.7   -5211.15  -5916.05\n",
      "  -5379.85  -5552.75  -7251.65  -7318.85  -5644.8   -4551.05  -3983.7\n",
      "  -3593.8   -3299.45  -3581.9   -2020.55   -862.05  -2446.5   -4114.95\n",
      "  -4718.7   -3914.05  -3215.8   -4070.85  -6189.4   -7450.45  -6958.35\n",
      "  -5853.75  -4687.55  -4024.65  -4281.2   -3954.65  -1979.6    -900.9\n",
      "  -2467.85  -3350.2   -2944.9   -2112.95  -2017.75  -3559.5   -5955.25\n",
      "  -8269.45  -8523.55  -6588.4   -5202.4   -4872.7   -4268.25  -3448.9\n",
      "  -1630.65   -732.2   -1951.25  -1919.75  -1612.45  -1178.8   -1519.35\n",
      "  -3925.95  -7036.4   -9546.95  -9247.    -7103.6   -5801.25  -4519.2\n",
      "  -3742.9   -2971.85  -1305.5    -834.4   -1693.3   -1434.3   -1059.1\n",
      "  -1198.05  -2632.    -5835.55  -8756.65  -9898.    -9110.85  -7008.75\n",
      "  -5048.75  -3332.7   -2736.3   -2107.7    -975.45   -878.5   -1564.5\n",
      "  -1372.    -1619.45  -2694.3   -4851.    -7682.5   -9316.65 -10291.4\n",
      "  -8623.3   -5726.7   -3584.7   -2431.1   -1855.35  -1649.2    -877.8\n",
      "   -673.75  -1465.45  -1979.25  -3356.15  -5380.55  -7326.2   -8797.95\n",
      " -10180.8   -9308.6   -6822.55  -4223.8   -2649.5   -1916.95  -1599.85\n",
      "  -1682.1    -869.05   -712.6   -1942.85  -3336.55  -5364.8   -7372.05\n",
      "  -8731.45  -9399.6   -9255.4   -7806.75  -5255.25  -3522.05  -2272.9\n",
      "  -1615.25  -1457.05  -1587.95   -864.15  -1048.95  -2906.75  -5411.\n",
      "  -7620.9   -8504.65  -8258.95  -7291.2   -6410.6   -5695.55  -4194.4\n",
      "  -3299.45  -2176.3   -1417.85  -1078.7   -1022.     -471.8   -1901.55\n",
      "  -5526.5   -8086.75  -8472.1   -7015.05  -5351.5   -3980.2   -4165.\n",
      "  -4126.5   -3491.6   -2584.05  -1890.35  -1513.4   -1280.65   -977.9\n",
      "   -424.2   -3743.95  -8029.7   -7952.35  -5661.6   -3339.    -2269.05\n",
      "  -1950.55  -2563.4   -2522.1   -2235.45  -1381.45  -1152.2   -1022.35\n",
      "  -1202.95  -1258.6    -758.45  -3331.3   -4541.95  -2848.65  -1139.25\n",
      "   -696.5    -491.75   -549.85   -820.75   -837.9    -643.3    -339.85\n",
      "   -243.25    -85.05   -294.7    -549.15   -331.1 ]\n"
     ]
    }
   ],
   "source": [
    "print test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Experimenting with different learing values\n",
    "\n",
    "## Thought: Maybe we can use the norm to quantify the effect of the learning rate on our w vector"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
