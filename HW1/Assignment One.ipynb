{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import third party libraries\n",
    "\n",
    "# Numerical library\n",
    "import numpy as np\n",
    "\n",
    "# Used for matrix inversion\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Allows for printing inline for jupyter notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load datasets and store in ndarray\n",
    "training_data = open('C:\\Users\\whitlock\\Downloads\\housing_train.txt','r')\n",
    "X_train = np.loadtxt(training_data)\n",
    "\n",
    "testing_data = open('C:\\Users\\whitlock\\Downloads\\housing_test.txt', 'r')\n",
    "X_test = np.loadtxt(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split off known target values\n",
    "y_train = X_train[:,13]\n",
    "y_test = X_test[:,13]\n",
    "\n",
    "# Add dimension to y_train and transpose\n",
    "y_train = y_train[np.newaxis].T\n",
    "y_test = y_test[np.newaxis].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(433L, 14L)\n"
     ]
    }
   ],
   "source": [
    "# Remove column 13 from X\n",
    "X_train = np.delete(X_train, 13, axis=1)\n",
    "X_test = np.delete(X_test, 13, axis=1)\n",
    "\n",
    "# Function to create array of dummy ones and returned \n",
    "# columnar vector\n",
    "def make_dummy_vector(target):\n",
    "    temp = np.ones(len(target))\n",
    "    return temp[np.newaxis].T\n",
    "\n",
    "# Create dummy 1 values\n",
    "dummy_train = make_dummy_vector(X_train)\n",
    "dummy_test = make_dummy_vector(X_test)\n",
    "\n",
    "# Add dummy data to feature matrices\n",
    "X_train = np.concatenate((dummy_train, X_train), axis=1)\n",
    "X_test = np.concatenate((dummy_test, X_test), axis=1)\n",
    "\n",
    "## WE SHOULD TALK ABOUT THIS AS A GROUP\n",
    "# Transpose X for further calculations\n",
    "#X_train = X_train.T\n",
    "#X_test = X_test.T\n",
    "\n",
    "print X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_train vector:\n",
      "0: [ 39.584]\n",
      "1: [-0.101]\n",
      "2: [ 0.046]\n",
      "3: [-0.003]\n",
      "4: [ 3.072]\n",
      "5: [-17.225]\n",
      "6: [ 3.711]\n",
      "7: [ 0.007]\n",
      "8: [-1.599]\n",
      "9: [ 0.374]\n",
      "10: [-0.016]\n",
      "11: [-1.024]\n",
      "12: [ 0.01]\n",
      "13: [-0.586]\n",
      " \r\n",
      "w_test vector:\n",
      "0: [ 16.494]\n",
      "1: [-0.03]\n",
      "2: [ 0.01]\n",
      "3: [-0.16]\n",
      "4: [ 1.129]\n",
      "5: [-6.583]\n",
      "6: [ 4.438]\n",
      "7: [-0.077]\n",
      "8: [-0.845]\n",
      "9: [-0.025]\n",
      "10: [ 0.005]\n",
      "11: [-0.7]\n",
      "12: [ 0.01]\n",
      "13: [-0.037]\n"
     ]
    }
   ],
   "source": [
    "## PART 2\n",
    "# Compute optimal weight vector w -- (X^T * X)^-1 (X^T * Y)\n",
    "def calc_w_vector(X, y):\n",
    "    return np.dot(inv(np.dot(X.T,X)), np.dot(X.T,y))\n",
    "\n",
    "def alt_calc(X,y):\n",
    "    return np.dot(np.dot(inv(X), inv(X.T), np.dot(X.T,y)))\n",
    "    \n",
    "# Limit printout to 3 decimal places\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Caculate w vectors\n",
    "w_train = calc_w_vector(X_train,y_train)\n",
    "w_test = calc_w_vector(X_test,y_test)\n",
    "\n",
    "# Print both weight vectors to console\n",
    "print 'w_train vector:'\n",
    "print('\\n'.join('{}: {}'.format(*k) for k in enumerate(w_train)))\n",
    "\n",
    "print ' \\r\\nw_test vector:'\n",
    "print('\\n'.join('{}: {}'.format(*k) for k in enumerate(w_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model: \r\n",
      "SSE: 9561.19 \r\n",
      "\n",
      "Testing Model: \r\n",
      "SSE: 852.51\n"
     ]
    }
   ],
   "source": [
    "## PART 3\n",
    "# Functions\n",
    "def calc_sse(X, y, w):\n",
    "    return np.dot(np.subtract(y, np.dot(X, w)).T, np.subtract(y,np.dot(X, w)))\n",
    "\n",
    "# Apply learned weight vectors\n",
    "target_func_train = np.dot(X_train, w_train)\n",
    "target_func_test = np.dot(X_test, w_test)\n",
    "\n",
    "# Print error output, not sure about the 0 values\n",
    "\n",
    "print 'Training Model: \\r\\nSSE: %.2f \\r\\n' % calc_sse(X_train, y_train, w_train)\n",
    "\n",
    "print 'Testing Model: \\r\\nSSE: %.2f' % calc_sse(X_test, y_test, w_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_train_no_dummy vector:\n",
      "0: [-0.098]\n",
      "1: [ 0.049]\n",
      "2: [-0.025]\n",
      "3: [ 3.451]\n",
      "4: [-0.355]\n",
      "5: [ 5.817]\n",
      "6: [-0.003]\n",
      "7: [-1.021]\n",
      "8: [ 0.227]\n",
      "9: [-0.012]\n",
      "10: [-0.388]\n",
      "11: [ 0.017]\n",
      "12: [-0.485]\n",
      " \r\n",
      "w_test_no_dummy vector:\n",
      "0: [ 0.011]\n",
      "1: [ 0.01]\n",
      "2: [-0.19]\n",
      "3: [ 1.126]\n",
      "4: [-1.137]\n",
      "5: [ 5.801]\n",
      "6: [-0.081]\n",
      "7: [-0.649]\n",
      "8: [-0.129]\n",
      "9: [ 0.008]\n",
      "10: [-0.572]\n",
      "11: [ 0.011]\n",
      "12: [ 0.072]\n"
     ]
    }
   ],
   "source": [
    "## PART 4\n",
    "# Repeating part 2 and 3 without a dummy features of 1's in X\n",
    "\n",
    "# Remove dummy column from both tables\n",
    "X_train_no_dummy = X_train[:, (1,2,3,4,5,6,7,8,9,10,11,12,13)]\n",
    "X_test_no_dummy = X_test[:, (1,2,3,4,5,6,7,8,9,10,11,12,13)]\n",
    "\n",
    "# Caculate w vectors\n",
    "w_train_no_dummy = calc_w_vector(X_train_no_dummy,y_train)\n",
    "w_test_no_dummy = calc_w_vector(X_test_no_dummy,y_test)\n",
    "\n",
    "# Print both weight vectors to console\n",
    "print 'w_train_no_dummy vector:'\n",
    "print('\\n'.join('{}: {}'.format(*k) for k in enumerate(w_train_no_dummy)))\n",
    "\n",
    "print ' \\r\\nw_test_no_dummy vector:'\n",
    "print('\\n'.join('{}: {}'.format(*k) for k in enumerate(w_test_no_dummy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Thoughts about results</h3>\n",
    "The above results make it seems like our model will be centered around the orgin beacuse we did not calcuate a true b value in the w vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model without Dummy: \r\n",
      "SSE: 10598.06 \r\n",
      "\n",
      "Testing Model without dummy: \r\n",
      "SSE: 883.85\n"
     ]
    }
   ],
   "source": [
    "## PART 4 cont.\n",
    "# Apply learned weight vectors\n",
    "target_func_train_no_dummy = np.dot(X_train_no_dummy, w_train_no_dummy)\n",
    "target_func_test_no_dummy = np.dot(X_test_no_dummy, w_test_no_dummy)\n",
    "\n",
    "# Print error output, not sure about the 0 values\n",
    "print 'Training Model without Dummy: \\r\\nSSE: %.2f \\r\\n' % calc_sse(X_train_no_dummy, y_train, w_train_no_dummy)\n",
    "\n",
    "print 'Testing Model without dummy: \\r\\nSSE: %.2f' % calc_sse(X_test_no_dummy, y_test, w_test_no_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate uniform additional uniformly distributed features\n",
    "feature_one = np.random.uniform(0,10,433)\n",
    "feature_two = np.random.uniform(0,100,433)\n",
    "feature_three = np.random.uniform(0,200,433)\n",
    "feature_four = np.random.uniform(0,400,433)\n",
    "feature_five = np.random.uniform(0,600,433)\n",
    "feature_six = np.random.uniform(0,800,433)\n",
    "feature_seven = np.random.uniform(0,1000,433)\n",
    "feature_eight = np.random.uniform(0,1200,433)\n",
    "feature_nine = np.random.uniform(0,1400,433)\n",
    "feature_ten = np.random.uniform(0,1600,433)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set up cases for 2,4,6,8,10 additional uniformly distributed features\n",
    "#two_feat = X_train[:, ()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Extra stuff below ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape\n",
    "print w_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Don't show scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print \"Printing X_train:\"\n",
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Printing y_train:\"\n",
    "print y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 1: Crime rate by town\n",
    "plt.scatter(X_train[:, 0],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 2: Residential land zoned for lots over 25,0000 sq. ft\n",
    "plt.scatter(X_train[:, 1],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiplotting feature 1 & 2\n",
    "plt.scatter(X_train[:, 0],y_train)\n",
    "plt.scatter(X_train[:, 1],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 3: Proportion of non-retail business acres per town\n",
    "plt.scatter(X_train[:, 2],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 4: Charles River dummy variable (= 1 if tract bounds river, 0 otherwise)\n",
    "plt.scatter(X_train[:, 3],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 5: Nitric oxides concentration (parts per 10 million)\n",
    "plt.scatter(X_train[:, 4],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 6: Average number fo rooms per dwelling\n",
    "plt.scatter(X_train[:, 5],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 7: Porportion of owner-occupied units built prior to 1940\n",
    "plt.scatter(X_train[:, 6],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 8: Weighted distances to five Boston employment centers\n",
    "plt.scatter(X_train[:, 7],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 9: Index of accessability to radial highways\n",
    "plt.scatter(X_train[:, 8],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 10: Full-value property-tax rate per $10,000\n",
    "plt.scatter(X_train[:, 9],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 11: Pupil-teacher ratio by town\n",
    "plt.scatter(X_train[:, 10],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 12: 1000(Bk - 0.63)^2 where Bk is the population fo blacks by town\n",
    "plt.scatter(X_train[:, 11],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 13: % lower status of the population\n",
    "plt.scatter(X_train[:, 12],y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
