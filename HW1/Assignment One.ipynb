{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import third party libraries\n",
    "\n",
    "# Numerical library\n",
    "import numpy as np\n",
    "\n",
    "# Machine learning library\n",
    "from sklearn import linear_model\n",
    "from sklearn import metrics\n",
    "\n",
    "# Used for matrix inversion\n",
    "from numpy.linalg import inv\n",
    "\n",
    "# Plotting library\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Allows for printing inline for jupyter notebook\n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load datasets and store in ndarray\n",
    "training_data = open('C:\\Users\\whitlock\\Downloads\\housing_train.txt','r')\n",
    "X_train = np.loadtxt(training_data)\n",
    "\n",
    "testing_data = open('C:\\Users\\whitlock\\Downloads\\housing_test.txt', 'r')\n",
    "X_test = np.loadtxt(testing_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split off known target values\n",
    "y_train = X_train[:,13]\n",
    "y_test = X_test[:,13]\n",
    "\n",
    "# Transpose row vector to columnar\n",
    "y_train = y_train[np.newaxis].T\n",
    "y_test = y_test[np.newaxis].T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove column 13 from X\n",
    "X_train = np.delete(X_train, 13, axis=1)\n",
    "X_test = np.delete(X_test, 13, axis=1)\n",
    "\n",
    "# Function to create array of dummy ones and returned \n",
    "# columnar vector\n",
    "def make_dummy_vector(target):\n",
    "    temp = np.ones(len(target))\n",
    "    return temp[np.newaxis].T\n",
    "\n",
    "# Create dummy 1 values\n",
    "dummy_train = make_dummy_vector(X_train)\n",
    "dummy_test = make_dummy_vector(X_test)\n",
    "\n",
    "# Add dummy data to feature matrices\n",
    "X_train = np.concatenate((dummy_train, X_train), axis=1)\n",
    "X_test = np.concatenate((dummy_test, X_test), axis=1)\n",
    "\n",
    "# Transpose X for further calculations\n",
    "#X_train = X_train.T\n",
    "#X_test = X_test.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_train vector:\n",
      "0: [ 39.584]\n",
      "1: [-0.101]\n",
      "2: [ 0.046]\n",
      "3: [-0.003]\n",
      "4: [ 3.072]\n",
      "5: [-17.225]\n",
      "6: [ 3.711]\n",
      "7: [ 0.007]\n",
      "8: [-1.599]\n",
      "9: [ 0.374]\n",
      "10: [-0.016]\n",
      "11: [-1.024]\n",
      "12: [ 0.01]\n",
      "13: [-0.586]\n",
      " \r\n",
      "w_test vector:\n",
      "0: [ 16.494]\n",
      "1: [-0.03]\n",
      "2: [ 0.01]\n",
      "3: [-0.16]\n",
      "4: [ 1.129]\n",
      "5: [-6.583]\n",
      "6: [ 4.438]\n",
      "7: [-0.077]\n",
      "8: [-0.845]\n",
      "9: [-0.025]\n",
      "10: [ 0.005]\n",
      "11: [-0.7]\n",
      "12: [ 0.01]\n",
      "13: [-0.037]\n"
     ]
    }
   ],
   "source": [
    "## PART 2\n",
    "# Compute optimal weight vector w -- (X^T * X)^-1 (X^T * Y)\n",
    "def calc_w_vector(X, y):\n",
    "    return np.dot(inv(np.dot(X.T,X)), np.dot(X.T,y))\n",
    "\n",
    "def alt_calc(X,y):\n",
    "    return np.dot(np.dot(inv(X), inv(X.T), np.dot(X.T,y)))\n",
    "    \n",
    "# Limit printout to 3 decimal places\n",
    "np.set_printoptions(precision=3)\n",
    "\n",
    "# Caculate w vectors\n",
    "w_train = calc_w_vector(X_train,y_train)\n",
    "w_test = calc_w_vector(X_test,y_test)\n",
    "\n",
    "# Print both weight vectors to console\n",
    "print 'w_train vector:'\n",
    "print('\\n'.join('{}: {}'.format(*k) for k in enumerate(w_train)))\n",
    "\n",
    "print ' \\r\\nw_test vector:'\n",
    "print('\\n'.join('{}: {}'.format(*k) for k in enumerate(w_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9561.191]]\n"
     ]
    }
   ],
   "source": [
    "print np.dot(np.subtract(y_train.T,np.dot(X_train,w_train).T),np.subtract(y_train,np.dot(X_train, w_train)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model: \r\n",
      "SSE: 9561.19\n",
      "Testing Model: \r\n",
      "SSE: 852.51\n"
     ]
    }
   ],
   "source": [
    "## PART 3\n",
    "# Functions\n",
    "def calc_sse(X, y, w):\n",
    "    return np.dot(np.subtract(y, np.dot(X, w)).T, np.subtract(y,np.dot(X, w)))\n",
    "\n",
    "def calc_mse(X, y, regr):\n",
    "    return np.mean((regr.predict(X) - y) ** 2)\n",
    "\n",
    "# Apply learned weight vectors\n",
    "target_func_train = np.dot(X_train, w_train)\n",
    "target_func_test = np.dot(X_test, w_test)\n",
    "\n",
    "# Create linear regression object\n",
    "#training_model = linear_model.LinearRegression()\n",
    "#testing_model = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "#training_model.fit(X_train,target_func_train)\n",
    "#testing_model.fit(X_test,target_func_test)\n",
    "\n",
    "# Print error output, not sure about the 0 values\n",
    "\n",
    "print 'Training Model: \\r\\nSSE: %.2f' % calc_sse(X_train, y_train, w_train)\n",
    "#print 'MSE: %.2f \\r\\n' % calc_mse(X_train, target_func_train)\n",
    "\n",
    "print 'Testing Model: \\r\\nSSE: %.2f' % calc_sse(X_test, y_test, w_test)\n",
    "#print 'MSE: %.2f' % calc_mse(X_test, target_func_test)\n",
    "\n",
    "#metrics.mean_squared_error(y_train,target_func_train)\n",
    "#metrics.mean_squared_error(y_test,target_func_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w_train_no_dummy vector:\n",
      "0: [-0.098]\n",
      "1: [ 0.049]\n",
      "2: [-0.025]\n",
      "3: [ 3.451]\n",
      "4: [-0.355]\n",
      "5: [ 5.817]\n",
      "6: [-0.003]\n",
      "7: [-1.021]\n",
      "8: [ 0.227]\n",
      "9: [-0.012]\n",
      "10: [-0.388]\n",
      "11: [ 0.017]\n",
      "12: [-0.485]\n",
      " \r\n",
      "w_test_no_dummy vector:\n",
      "0: [ 0.011]\n",
      "1: [ 0.01]\n",
      "2: [-0.19]\n",
      "3: [ 1.126]\n",
      "4: [-1.137]\n",
      "5: [ 5.801]\n",
      "6: [-0.081]\n",
      "7: [-0.649]\n",
      "8: [-0.129]\n",
      "9: [ 0.008]\n",
      "10: [-0.572]\n",
      "11: [ 0.011]\n",
      "12: [ 0.072]\n"
     ]
    }
   ],
   "source": [
    "## PART 4\n",
    "# Repeating part 2 and 3 without a dummy features of 1's in X\n",
    "\n",
    "# Remove dummy column from both tables\n",
    "X_train_no_dummy = X_train[:, (1,2,3,4,5,6,7,8,9,10,11,12,13)]\n",
    "X_test_no_dummy = X_test[:, (1,2,3,4,5,6,7,8,9,10,11,12,13)]\n",
    "\n",
    "# Caculate w vectors\n",
    "w_train_no_dummy = calc_w_vector(X_train_no_dummy,y_train)\n",
    "w_test_no_dummy = calc_w_vector(X_test_no_dummy,y_test)\n",
    "\n",
    "# Print both weight vectors to console\n",
    "print 'w_train_no_dummy vector:'\n",
    "print('\\n'.join('{}: {}'.format(*k) for k in enumerate(w_train_no_dummy)))\n",
    "\n",
    "print ' \\r\\nw_test_no_dummy vector:'\n",
    "print('\\n'.join('{}: {}'.format(*k) for k in enumerate(w_test_no_dummy)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Thoughts about results</h3>\n",
    "The above results make it seems like our model will be centered around the orgin beacuse we did not calcuate a true b value in the w vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model without Dummy: \r\n",
      "SSE: 10598.06\n",
      "Testing Model without dummy: \r\n",
      "SSE: 883.85\n"
     ]
    }
   ],
   "source": [
    "## PART 4 cont.\n",
    "# Apply learned weight vectors\n",
    "target_func_train_no_dummy = np.dot(X_train_no_dummy, w_train_no_dummy)\n",
    "target_func_test_no_dummy = np.dot(X_test_no_dummy, w_test_no_dummy)\n",
    "\n",
    "# Create linear regression object\n",
    "#training_model_no_dummy = linear_model.LinearRegression()\n",
    "#testing_model_no_dummy = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "#training_model_no_dummy.fit(X_train_no_dummy,target_func_train_no_dummy)\n",
    "#testing_model_no_dummy.fit(X_test_no_dummy,target_func_test_no_dummy)\n",
    "\n",
    "# Print error output, not sure about the 0 values\n",
    "print 'Training Model without Dummy: \\r\\nSSE: %.2f' % calc_sse(X_train_no_dummy, y_train, w_train_no_dummy)\n",
    "#print 'MSE: %.2f \\r\\n' % calc_mse(X_train_no_dummy, target_func_train, training_model_no_dummy)\n",
    "\n",
    "print 'Testing Model without dummy: \\r\\nSSE: %.2f' % calc_sse(X_test_no_dummy, y_test, w_test_no_dummy)\n",
    "#print 'MSE: %.2f' % calc_mse(X_test_no_dummy, target_func_test_no_dummy, training_model_no_dummy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate artificial random features\n",
    "feature_one = np.random.uniform(0,10,433)\n",
    "feature_two = np.random.uniform(0,100,433)\n",
    "feature_three = np.random.uniform(0,200,433)\n",
    "feature_four = np.random.uniform(0,400,433)\n",
    "feature_five = np.random.uniform(0,600,433)\n",
    "feature_six = np.random.uniform(0,800,433)\n",
    "feature_seven = np.random.uniform(0,1000,433)\n",
    "feature_eight = np.random.uniform(0,1200,433)\n",
    "feature_nine = np.random.uniform(0,1400,433)\n",
    "feature_ten = np.random.uniform(0,1600,433)\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 40.405  97.378  53.28   37.881  78.661  95.919  19.879  76.221   6.594\n",
      "  67.607  56.063  47.277   1.678  34.094  14.36   19.545  14.089  60.37\n",
      "  87.986  83.655  90.341  37.575  50.653  30.14   33.247  61.553  30.901\n",
      "   4.556  73.344  39.386  34.636   9.628  42.807  72.186  52.76   48.793\n",
      "  28.463  71.113  15.677  23.036  91.2    19.465  40.929  41.804   2.536\n",
      "  89.094  99.139  60.074  40.997  53.743  67.213  11.499  34.518  53.427\n",
      "  93.652  64.953  69.658  90.974  22.39   82.13   15.963  81.942   6.271\n",
      "  85.805  85.081   9.225  45.172  13.063  45.98   34.24   66.047  71.682\n",
      "  94.824  31.622   3.224  57.93   53.668  22.952  74.273  12.312  75.107\n",
      "  75.641  62.008  94.114  32.375  81.131  23.556   2.886  53.953  26.115\n",
      "  11.347  36.322   4.691  12.712  58.334  11.55   77.611  46.335  41.488\n",
      "  91.114  82.205  54.193  52.847  36.12   23.005  57.785   5.572  37.728\n",
      "  86.849  47.532  32.147  19.071  89.515  95.553  60.944  77.001  71.579\n",
      "  53.525   4.299   6.482  54.765  56.166  50.31   45.574  53.504  60.352\n",
      "  85.484  43.561  66.497  33.034   1.252  86.292  58.438  57.789  29.031\n",
      "  79.477  33.114  74.103  59.267  37.138  95.378  98.771  89.503  31.588\n",
      " 100.     10.908  85.823  54.917  15.355  16.554  91.007  22.255  79.109\n",
      "  11.955  81.857  31.341  31.663  45.985  41.807  15.444   4.602  48.615\n",
      "  26.832  55.557  10.506  52.301  82.128  31.234  43.248  85.851  54.009\n",
      "  16.19   85.628  63.463  96.366  61.195  16.175  89.85   80.043  46.904\n",
      "  29.103   8.797  25.159  19.664  19.289  67.535  34.575  48.26   24.753\n",
      "  97.496  66.044   5.829  16.728  41.353  76.446  68.715   5.333  94.347\n",
      "   2.51   45.191  35.791  68.993  39.032  62.053  28.138  10.379  54.893\n",
      "  42.408  38.141  13.217  20.236  12.329  78.911  60.291  22.889  28.991\n",
      "  81.576  26.968  59.828  29.239  19.975  36.238  28.903  89.543  60.603\n",
      "  20.173  17.343  40.369  36.934  99.929  70.234  80.498  45.364  68.424\n",
      "  64.476  45.523  77.924  52.305  76.913  78.159  60.555  35.649  88.166\n",
      "  35.702  31.305  22.394  93.525  53.584   6.174  50.334  20.424  41.351\n",
      "   2.954  61.342  12.699   4.262  59.021  39.736  84.745  42.477  90.469\n",
      "  32.492   6.17   38.711  47.13   38.936  88.546  13.     93.753  40.228\n",
      "  49.173  73.228  34.727  19.669   5.077  79.208  26.736  64.377  55.82\n",
      "  93.413  81.12   52.761   4.292  88.34   11.075  89.098  24.677   2.107\n",
      "  65.211  56.055  79.087  83.595  20.725  55.002  73.551  65.642  15.908\n",
      "  78.925  55.589   4.927  81.037  75.925  54.791  34.468   8.338  24.126\n",
      "  54.418  95.384  69.02   12.719  32.038  51.377  15.705  28.224  16.694\n",
      "  35.605  97.79   88.717   2.752  42.8    78.932  29.21   78.854  87.887\n",
      "  32.343  37.602  27.772  62.781  60.82   35.094  19.395  30.533  32.505\n",
      "  49.882  59.456  41.349  31.416  19.007  16.899  51.362  52.502  38.521\n",
      "  25.877  82.847  60.253  37.25   83.748   6.113  66.993  92.021  23.809\n",
      "  71.212  66.069  63.683  60.638  23.88   52.088  50.003  16.677   5.471\n",
      "  93.11   95.125  46.584  92.571  67.017  29.355  79.149  89.482  65.884\n",
      "  51.843   2.379  68.428  51.5    43.423  90.439  78.308  88.082  76.72\n",
      "  94.388  49.786  24.378  41.024  75.011  58.622  96.682  55.028  47.793\n",
      "  42.794   4.459  92.622  58.33   15.706  58.831  28.731  88.32   68.219\n",
      "  13.806  83.928  70.114  46.03   49.089  87.572  43.84   29.057  13.087\n",
      "  77.898  10.283  29.978  42.049  99.858  60.087  20.081   5.496  16.678\n",
      "  71.519  22.987  56.785  36.325  15.817  30.45   61.469  77.262  81.291\n",
      "   3.831  37.866  20.036  96.12   86.409  85.815  89.13   39.017  75.626\n",
      "  37.743]\n"
     ]
    }
   ],
   "source": [
    "print feature_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Coefficients\n",
    "print('Coefficients: \\n' , regr.coef_)\n",
    "\n",
    "# Mean squared error\n",
    "print(\"Mean squared error: %.2f\" \n",
    "      % np.mean((regr.predict(X_test) - y_test) ** 2))\n",
    "\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % regr.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print (regr.predict(X_test[:1,]) - y_test[:1,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train[:,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.shape\n",
    "print w_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print X_train.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# EXTRA MATERIAL BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Don't show scientific notation\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "print \"Printing X_train:\"\n",
    "print X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"Printing y_train:\"\n",
    "print y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 1: Crime rate by town\n",
    "plt.scatter(X_train[:, 0],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 2: Residential land zoned for lots over 25,0000 sq. ft\n",
    "plt.scatter(X_train[:, 1],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Multiplotting feature 1 & 2\n",
    "plt.scatter(X_train[:, 0],y_train)\n",
    "plt.scatter(X_train[:, 1],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 3: Proportion of non-retail business acres per town\n",
    "plt.scatter(X_train[:, 2],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 4: Charles River dummy variable (= 1 if tract bounds river, 0 otherwise)\n",
    "plt.scatter(X_train[:, 3],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 5: Nitric oxides concentration (parts per 10 million)\n",
    "plt.scatter(X_train[:, 4],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 6: Average number fo rooms per dwelling\n",
    "plt.scatter(X_train[:, 5],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 7: Porportion of owner-occupied units built prior to 1940\n",
    "plt.scatter(X_train[:, 6],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 8: Weighted distances to five Boston employment centers\n",
    "plt.scatter(X_train[:, 7],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 9: Index of accessability to radial highways\n",
    "plt.scatter(X_train[:, 8],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 10: Full-value property-tax rate per $10,000\n",
    "plt.scatter(X_train[:, 9],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 11: Pupil-teacher ratio by town\n",
    "plt.scatter(X_train[:, 10],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 12: 1000(Bk - 0.63)^2 where Bk is the population fo blacks by town\n",
    "plt.scatter(X_train[:, 11],y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot feature 13: % lower status of the population\n",
    "plt.scatter(X_train[:, 12],y_train)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
